# Multi-armed bandit problem
https://en.wikipedia.org/wiki/Multi-armed_bandit

# To do:
- [x] OOP base
- [x] Epsilon-greedy
- [x] Epsilon_n-greedy
- [x] UCB1
- [x] Softmax
- [x] Pursuit
- [ ] Reinforcement Comparison
- [x] Thompson Sampling
- [ ] Play the winner
- [ ] One expert
- [ ] Experts

- [x] Regret calculation
- [x] Conversion calculation
