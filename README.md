# Multi-armed bandit problem
https://en.wikipedia.org/wiki/Multi-armed_bandit

# To do:
- [x] OOP base
- [ ] Epsilon-greedy
- [ ] Epsilon_n-greedy
- [ ] UCB1
- [ ] Softmax
- [ ] Pursuit
- [ ] Reinforcement Comparison
- [ ] Thompson Sampling
- [ ] Play the winner
- [ ] One expert
- [ ] Experts
